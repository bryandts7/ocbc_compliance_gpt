{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Store Data to Vector Store (OJK)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ini cara untuk storing ke Redis, tapi untuk [Load](#load) Document beda-beda untuk tiap data BI, OJK, dan SIKEPO. Jadi buat sendiri function `extract_all_documents_in_directory` nya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import get_config\n",
    "from utils.models import ModelName, get_model\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ModelName.AZURE_OPENAI\n",
    "llm_model, embed_model = get_model(model_name=model_name, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_dir = './data/documents/'\n",
    "pickle_path = './data/pickles/'\n",
    "metadata_path = './data/metadata/files_metadata.csv'\n",
    "\n",
    "LOAD_PICKLE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load**\n",
    "\n",
    "Untuk SIKEPO dan BI beda cara extract documentsnya, file document_extractor buat sendiri :D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.documents_extractor.documents_extract_ojk import extract_all_documents_in_directory\n",
    "\n",
    "if not LOAD_PICKLE:\n",
    "    documents = extract_all_documents_in_directory(documents_dir, metadata_path, treshold=0.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.documents_split import document_splitter\n",
    "import pickle\n",
    "\n",
    "\n",
    "if not LOAD_PICKLE:\n",
    "    all_splits = document_splitter(docs=documents)\n",
    "    all_splits1 = sorted(all_splits, key=lambda x: (x.metadata['doc_id'], x.metadata.get('page_number', '0')))\n",
    "    # Open a file and use dump() \n",
    "    with open(pickle_path + 'documents1.pkl', 'wb') as file:\n",
    "\n",
    "        # A new file will be created\n",
    "        pickle.dump(all_splits1, file) \n",
    "\n",
    "# Open the file in binary mode \n",
    "with open(pickle_path + 'documents1.pkl', 'rb') as file:\n",
    "    \n",
    "    # Call load method to deserialze \n",
    "    all_splits = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113052"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'doc_id': 1, 'title': 'Dasar Penilaian Investasi Dana Pensiun', 'sector': 'IKNB', 'subsector': 'Dana Pensiun', 'regulation_type': 'Surat Edaran OJK', 'regulation_number': '4/SEOJK.05/2024', 'effective_date': '1 Juli 2024', 'file_url': 'https://www.ojk.go.id/id/regulasi/Documents/Pages/Dasar-Penilaian-Investasi-Dana-Pensiun/SEOJK%204-SEOJK.05-2024%20Dasar%20Penilaian%20Investasi%20Dana%20Pensiun.pdf', 'page_number': 1}, page_content=\"metadata={'doc_id': 1, 'title': 'Dasar Penilaian Investasi Dana Pensiun', 'sector': 'IKNB', 'subsector': 'Dana Pensiun', 'regulation_type': 'Surat Edaran OJK', 'regulation_number': '4/SEOJK.05/2024', 'effective_date': '1 Juli 2024', 'file_url': 'https://www.ojk.go.id/id/regulasi/Documents/Pages/Dasar-Penilaian-Investasi-Dana-Pensiun/SEOJK%204-SEOJK.05-2024%20Dasar%20Penilaian%20Investasi%20Dana%20Pensiun.pdf', 'page_number': 1}\\n \\n \\n \\n \\n \\nYth.  \\nPengurus Dana Pensiun \\ndi tempat. \\n \\nSALINAN \\nSURAT EDARAN OTORITAS JASA KEUANGAN \\nREPUBLIK INDONESIA \\nNOMOR 4/SEOJK.05/2024 \\nTENTANG \\nDASAR PENILAIAN INVESTASI DANA PENSIUN \\n \\nSehubungan dengan amanat ketentuan Pasal 150 ayat (5) Peraturan \\nOtoritas Jasa Keuangan Nomor 27 Tahun 2023 tentang Penyelenggaraan \\nUsaha Dana Pensiun (Lembaran Negara Republik Indonesia Tahun 2023 \\nNomor 45/OJK, Tambahan Lembaran Negara Republik Indonesia Nomor \\n67/OJK), perlu untuk menyesuaikan ketentuan mengenai dasar penilaian\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Storing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading from idx: 0\n",
      "Loaded 1-100 documents\n",
      "Loaded 101-200 documents\n",
      "Loaded 201-300 documents\n",
      "Loaded 301-400 documents\n",
      "Loaded 401-500 documents\n",
      "Loaded 501-600 documents\n",
      "Loaded 601-700 documents\n",
      "Loaded 701-800 documents\n",
      "Loaded 801-900 documents\n",
      "Loaded 901-1000 documents\n"
     ]
    }
   ],
   "source": [
    "from databases.vector_store import RedisIndexManager\n",
    "\n",
    "redis = RedisIndexManager(index_name='ojk', embed_model=embed_model, config=config, db_id=0)\n",
    "\n",
    "# redis.delete_index()\n",
    "redis.store_vector_index(docs=all_splits, batch_size=100) # Kalau error 'Redis failed to connect: Index does not exist.' ubah isi start_store_idx_indexname.txt menjadi 0\n",
    "vector_store = redis.load_vector_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
